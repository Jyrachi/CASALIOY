#################################
#       DIRECTORY SETTINGS      #
#################################
# Vertex database folder name. Database will be created after running ingest.py on your documents.
PERSIST_DIRECTORY=db
# The directory your documents are in. (Currently supporting TXT,CSV,PDF)
# Note: You can define the directory as an argument instead. Ex: "python ./ingest.py 'c:/documents'"
DOCUMENTS_DIRECTORY=source_documents

#################################
#       LLM MODEL SETTINGS      #
#################################
# Absolute path to your llama supported embeddings model.
# Can be the same as your LLM's MODEL_PATH below if using LlamaCpp for your model type.
LLAMA_EMBEDDINGS_MODEL=models/ggml-model-q4_0.bin
# Your LLM model type. (Currently supports GPT4All or LlamaCpp)
# MODEL_TYPE=LlamaCpp 
MODEL_TYPE=GPT4All
# Absolute path to your GPT4All or LlamaCpp LLM model
MODEL_PATH=models/ggml-gpt4all-j-v1.3-groovy.bin
# Context size for both the vertex datbase and the llm model seperately in one value.
# Increase this value only if you are getting context size errors. (Try just doubling it.)
# Default is 1024
MODEL_N_CTX=1024
# Temperature between 0 and 1 for your GPT4All or LlamaCpp LLM model.
# 0=Logical 1=Creative
# Default is 0.8
MODEL_TEMP=0.8
# Stop sequences for your GPT4All or LlamaCpp LLM model.
# Stop based on certain characters or strings.
# This stops the model from writing multiple lines and continuing.
# \n is for new lines and \t is for tabs.
MODEL_STOP=\n,\t